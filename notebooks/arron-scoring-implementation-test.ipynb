{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import librosa\n",
    "import youtube_dl\n",
    "import os\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change dir and instance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arron/code/PlexedLive/mixs/models/Conditioned-Source-Separation-LaSAFT\n"
     ]
    }
   ],
   "source": [
    "%cd ../models/Conditioned-Source-Separation-LaSAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasaft.source_separation.conditioned.cunet.models.dcun_tfc_gpocm_lasaft import DCUN_TFC_GPoCM_LaSAFT_Framework\n",
    "\n",
    "args = {}\n",
    "\n",
    "# FFT params\n",
    "args['n_fft'] = 2048\n",
    "args['hop_length'] = 1024\n",
    "args['num_frame'] = 128\n",
    "\n",
    "# SVS Framework\n",
    "args['spec_type'] = 'complex'\n",
    "args['spec_est_mode'] = 'mapping'\n",
    "\n",
    "# Other Hyperparams\n",
    "args['optimizer'] = 'adam'\n",
    "args['lr'] = 0.001\n",
    "args['dev_mode'] = False\n",
    "args['train_loss'] = 'spec_mse'\n",
    "args['val_loss'] = 'raw_l1'\n",
    "\n",
    "# DenseNet Hyperparams\n",
    "\n",
    "args ['n_blocks'] = 7\n",
    "args ['input_channels'] = 4\n",
    "args ['internal_channels'] = 24\n",
    "args ['first_conv_activation'] = 'relu'\n",
    "args ['last_activation'] = 'identity'\n",
    "args ['t_down_layers'] = None\n",
    "args ['f_down_layers'] = None\n",
    "args ['tif_init_mode'] = None\n",
    "\n",
    "# TFC_TDF Block's Hyperparams\n",
    "args['n_internal_layers'] =5\n",
    "args['kernel_size_t'] = 3\n",
    "args['kernel_size_f'] = 3\n",
    "args['tfc_tdf_activation'] = 'relu'\n",
    "args['bn_factor'] = 16\n",
    "args['min_bn_units'] = 16\n",
    "args['tfc_tdf_bias'] = True\n",
    "args['num_tdfs'] = 6\n",
    "args['dk'] = 32\n",
    "\n",
    "args['control_vector_type'] = 'embedding'\n",
    "args['control_input_dim'] = 4\n",
    "args['embedding_dim'] = 32\n",
    "args['condition_to'] = 'decoder'\n",
    "\n",
    "args['control_n_layer'] = 4\n",
    "args['control_type'] = 'dense'\n",
    "args['pocm_type'] = 'matmul'\n",
    "args['pocm_norm'] = 'batch_norm'\n",
    "\n",
    "\n",
    "model = DCUN_TFC_GPoCM_LaSAFT_Framework(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint('pretrained/gpocm_lasaft.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising song from musb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dir = '../../raw_data/musdb18/test/'\n",
    "track_name = 'Tom McKenzie - Directions.stem.mp4'\n",
    "\n",
    "\n",
    "# old code below\n",
    "\n",
    "audio, rate = librosa.load(f'{track_dir}{track_name}', mono=False, sr=None)\n",
    "\n",
    "# audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import musdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = musdb.DB(root='../../raw_data/musdb18/samples', subsets='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = DB.tracks[0].audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = DB.tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13779968, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below takes the audio, runs the model to split audio and outputs the numpy array of the split audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_all(audio):\n",
    "    '''\n",
    "    you can add or remove what ever you want in this loop\n",
    "    using the keys, vocals, drums, bass and other\n",
    "    you can also combine them \n",
    "    '''\n",
    "    \n",
    "    print('vocals')\n",
    "    vocals = model.separate_track(audio, 'vocals') \n",
    "\n",
    "    print('drums')\n",
    "    drums = model.separate_track(audio, 'drums') \n",
    "\n",
    "\n",
    "    print('bass')\n",
    "    bass = model.separate_track(audio, 'bass') \n",
    "\n",
    "\n",
    "    print('other')\n",
    "    other = model.separate_track(audio, 'other') \n",
    "\n",
    "    \n",
    "    return vocals, drums, bass, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocals\n",
      "drums\n",
      "bass\n",
      "other\n"
     ]
    }
   ],
   "source": [
    "vocals_test, drums_test, bass_test, other_test = separate_all(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11142144, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = {\n",
    "    'vocals': vocals_test,\n",
    "    'drums': drums_test,\n",
    "    'bass': bass_test,\n",
    "    'accompaniment': other_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arron/code/PlexedLive/mixs/models/Conditioned-Source-Separation-LaSAFT\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../notebooks/test_files/outputs', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = np.load('../../notebooks/test_files/outputs.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_dir = '../../notebooks/test_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import museval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arron/.pyenv/versions/mixs/lib/python3.7/site-packages/museval/aggregate.py:409: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  ['name']\n"
     ]
    }
   ],
   "source": [
    "results = museval.EvalStore(frames_agg='median', tracks_agg='median')\n",
    "results.add_track(museval.eval_mus_track(track, estimates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aggrated Scores (median over frames, median over tracks)\n",
       "drums           ==> SDR:   3.463  SIR:  18.229  ISR:   5.281  SAR:   3.337  \n",
       "bass            ==> SDR:  13.900  SIR:  30.086  ISR:  14.640  SAR:  12.680  \n",
       "vocals          ==> SDR:   7.021  SIR:  11.544  ISR:  16.015  SAR:   7.765  \n",
       "accompaniment   ==> SDR:   3.253  SIR:  15.508  ISR:   4.705  SAR:   4.542  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.save(path='../../notebooks/test_files/test.pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accompaniment</th>\n",
       "      <td>155.5</td>\n",
       "      <td>7.746779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bass</th>\n",
       "      <td>155.5</td>\n",
       "      <td>13.410577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drums</th>\n",
       "      <td>155.5</td>\n",
       "      <td>7.756908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocals</th>\n",
       "      <td>155.5</td>\n",
       "      <td>8.121085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time      score\n",
       "target                         \n",
       "accompaniment  155.5   7.746779\n",
       "bass           155.5  13.410577\n",
       "drums          155.5   7.756908\n",
       "vocals         155.5   8.121085"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('../../notebooks/test_files/test.pandas').groupby('target').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
