{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Spleeter can separate audio into 2, 4, or 5 stems\n",
    "2. Dependent on installation of *ffmpeg* & *libsndfile*\n",
    "3. If you have issues with ffmpeg probe, pip uninstall ffmpeg-python then pip install ffmpeg-python\n",
    "4. pip install spleeter\n",
    "5. There is a conda install (and a conda install for running on GPU) but I was not able to get it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spleeter.separator import Separator\n",
    "from spleeter.audio.adapter import  get_default_audio_adapter\n",
    "import librosa\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import youtube_dl\n",
    "import os\n",
    "import museval\n",
    "import musdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-stem implementation with one song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = Separator('spleeter:4stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dir = '../raw_data/small_sample/train'\n",
    "track_name = \"James May - On The Line.stem.mp4\"\n",
    "audio, rate = librosa.load(f'{track_dir}/{track_name}', mono=False, sr=None)\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_loader = get_default_audio_adapter()\n",
    "waveform, _ = audio_loader.load(f'{track_dir}/{track_name}', sample_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prediction = separator.separate(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When ready to do multiple predictions and save output, uncomment line below:\n",
    "\n",
    "# separator.separate_to_file('/path/to/audio', '/path/to/output/directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_audio(prediction):\n",
    "    for key, val in prediction.items():\n",
    "        print(key)\n",
    "        display(Audio(val.T, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_audio(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-stem implementation with one song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator_5 = Separator('spleeter:5stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"gxEPV4kolz0\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] gxEPV4kolz0: Downloading webpage\n",
      "[youtube] gxEPV4kolz0: Downloading webpage\n",
      "[download] Billy Joel - Piano Man (Video).wav has already been downloaded\n",
      "[download] 100% of 5.57MiB\n",
      "Done downloading...\n",
      "[ffmpeg] Post-process file Billy Joel - Piano Man (Video).wav exists, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15062017)\n"
     ]
    }
   ],
   "source": [
    "def my_hook(d):\n",
    "    if d['status'] == 'finished':\n",
    "        print('Done downloading...')\n",
    "\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '44100',\n",
    "    }],\n",
    "    'outtmpl': '%(title)s.wav',\n",
    "    'progress_hooks': [my_hook],\n",
    "}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    info = ydl.extract_info(url, download=False)\n",
    "    status = ydl.download([url])\n",
    "\n",
    "audio, rate = librosa.load(info.get('title', None) + '.wav', sr=44100, mono=False)\n",
    "print(audio.shape)\n",
    "display(Audio(audio, rate=rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_loader = get_default_audio_adapter()\n",
    "waveform_5, _ = audio_loader.load(info.get('title', None) + '.wav', sample_rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prediction_5 = separator_5.separate(waveform_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_audio(prediction_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-stem implementation with multiple songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator_4 = Separator('spleeter:4stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for drums_spectrogram\n",
      "INFO:tensorflow:Apply unet for bass_spectrogram\n",
      "INFO:tensorflow:Apply unet for other_spectrogram\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:Downloading model archive https://github.com/deezer/spleeter/releases/download/v1.4.0/4stems.tar.gz\n",
      "INFO:spleeter:Validating archive checksum\n",
      "INFO:spleeter:Extracting downloaded 4stems archive\n",
      "INFO:spleeter:4stems model file(s) extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from pretrained_models\\4stems\\model\n",
      "Wall time: 14min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "track_dir = '../raw_data/small_sample/test'\n",
    "audio_loader = get_default_audio_adapter()\n",
    "tracks = tracks = [track for track in os.listdir(track_dir) if track.endswith(\".mp4\")]\n",
    "predictions_4 = []\n",
    "for track in tracks:\n",
    "    waveform, rate = audio_loader.load(f'{track_dir}/{track}', sample_rate=None)\n",
    "    predictions_4.append(separator_4.separate(waveform))\n",
    "\n",
    "len(predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocals': array([[ 8.2174216e-07,  2.3738392e-06],\n",
       "        [-5.7736829e-06, -4.0965188e-06],\n",
       "        [-7.4836057e-06, -7.2264124e-06],\n",
       "        ...,\n",
       "        [-4.9810780e-07, -7.4118924e-07],\n",
       "        [-6.9197563e-07, -9.0814711e-07],\n",
       "        [ 2.6827118e-08, -2.2358851e-07]], dtype=float32),\n",
       " 'drums': array([[ 2.0232576e-06,  3.0989161e-06],\n",
       "        [-5.2794276e-06, -4.0503533e-06],\n",
       "        [-5.8765031e-06, -5.1982811e-06],\n",
       "        ...,\n",
       "        [-2.2698906e-08, -2.1638142e-08],\n",
       "        [ 2.4460123e-08,  2.3717826e-08],\n",
       "        [ 1.8263480e-08,  1.4560887e-08]], dtype=float32),\n",
       " 'bass': array([[ 1.9819734e-06,  3.2598357e-06],\n",
       "        [-4.9282285e-06, -3.7297330e-06],\n",
       "        [-5.2122541e-06, -4.6598102e-06],\n",
       "        ...,\n",
       "        [ 4.7658379e-08,  4.2528288e-08],\n",
       "        [ 1.8116408e-07,  1.8178979e-07],\n",
       "        [ 2.7007419e-08,  2.2057860e-08]], dtype=float32),\n",
       " 'other': array([[ 2.1506859e-05,  2.2276516e-05],\n",
       "        [-2.6900949e-05, -2.7346205e-05],\n",
       "        [-2.9021370e-05, -3.2684053e-05],\n",
       "        ...,\n",
       "        [ 4.9498300e-07,  7.9787839e-07],\n",
       "        [ 3.5581374e-07,  5.5868725e-07],\n",
       "        [-1.1957867e-07,  8.3891884e-08]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_4[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of 4-stem model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/njeri/code/ngachago/mixs/notebooks\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_files/spleeter_4', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_4 = np.load('test_files/spleeter_4.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB = musdb.DB(root='../raw_data/small_sample', subsets='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6f105f41b5d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions_4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtracks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_track\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmuseval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_mus_track\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\museval\\__init__.py\u001b[0m in \u001b[0;36meval_mus_track\u001b[1;34m(track, user_estimates, output_dir, mode, win, hop)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0maudio_reference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         SDR, ISR, SIR, SAR = evaluate(\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0maudio_reference\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0maudio_estimates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\museval\\__init__.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(references, estimates, win, hop, mode, padding)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_or_truncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     SDR, ISR, SIR, SAR, _ = metrics.bss_eval(\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mestimates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\museval\\metrics.py\u001b[0m in \u001b[0;36mbss_eval\u001b[1;34m(reference_sources, estimated_sources, window, hop, compute_permutation, filters_len, framewise_filters, bsseval_sources_version)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mframewise_filters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# compute filters on whole signals if no framewise filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_GsfC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m         \u001b[0mCj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_Cj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\museval\\metrics.py\u001b[0m in \u001b[0;36mcompute_GsfC\u001b[1;34m(win)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_GsfC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnsampl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# First compute the references correlations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         G, sf = _compute_reference_correlations(\n\u001b[0m\u001b[0;32m    258\u001b[0m             \u001b[0mreference_sources\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\museval\\metrics.py\u001b[0m in \u001b[0;36m_compute_reference_correlations\u001b[1;34m(reference_sources, filters_len)\u001b[0m\n\u001b[0;32m    535\u001b[0m     ):\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mssf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m         \u001b[0mssf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         ss = toeplitz(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_4 = museval.EvalStore(frames_agg='mean', tracks_agg='mean')\n",
    "for idx, estimate in np.ndenumerate(predictions_4):\n",
    "    results_4.add_track(museval.eval_mus_track(DB.tracks[idx], estimate))\n",
    "                \n",
    "results_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.save(path='test_files/spleeter_4.pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-stem implementation with multiple songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator_5 = Separator('spleeter:5stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\njeri\\.venvs\\mixs_env\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for piano_spectrogram\n",
      "INFO:tensorflow:Apply unet for drums_spectrogram\n",
      "INFO:tensorflow:Apply unet for bass_spectrogram\n",
      "INFO:tensorflow:Apply unet for other_spectrogram\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models\\5stems\\model\n",
      "Wall time: 8min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictions_5 = []\n",
    "for track in tracks:\n",
    "    waveform, rate = audio_loader.load(f'{track_dir}/{track}', sample_rate=None)\n",
    "    predictions_5.append(separator_5.separate(waveform))\n",
    "\n",
    "len(predictions_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocals': array([[-5.9437498e-06,  2.7136530e-06],\n",
       "        [-1.0363790e-05,  3.4015993e-06],\n",
       "        [-9.4779962e-06,  1.7994013e-06],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00]], dtype=float32),\n",
       " 'piano': array([[-7.79070746e-08,  9.77548495e-08],\n",
       "        [-1.61176175e-07,  1.11829479e-07],\n",
       "        [-1.13123804e-07,  5.66841578e-08],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00]], dtype=float32),\n",
       " 'drums': array([[-6.1507666e-07,  5.6881100e-07],\n",
       "        [-7.6188149e-07,  4.4469303e-07],\n",
       "        [-7.5826102e-07,  3.8342640e-07],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00]], dtype=float32),\n",
       " 'bass': array([[-8.1884895e-07,  8.6586368e-07],\n",
       "        [-9.2851548e-07,  8.7294569e-07],\n",
       "        [-8.9386748e-07,  8.0035966e-07],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00]], dtype=float32),\n",
       " 'other': array([[-1.6362015e-05,  2.0029252e-06],\n",
       "        [-2.6067055e-05,  1.8200261e-06],\n",
       "        [-3.3143453e-05,  4.0727363e-07],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00]], dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_5[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of 5-stem model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_files/spleeter_5', predictions_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_5 = np.load('test_files/spleeter_5.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_5 = museval.EvalStore(frames_agg='mean', tracks_agg='mean')\n",
    "for idx, estimate in np.ndenumerate(predictions_5):\n",
    "    results_5.add_track(museval.eval_mus_track(DB.tracks[idx], estimate))\n",
    "                \n",
    "results_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5.save(path='test_files/spleeter_5.pandas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
